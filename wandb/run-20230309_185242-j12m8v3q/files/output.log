
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Using custom data configuration default-8e0070c28d494a17
Found cached dataset text (C:/Users/Theresa/.cache/huggingface/datasets/text/default-8e0070c28d494a17/0.0.0/99cc88223027054f94ce0c7fd69d10eb172910fa0615671283a3c8e5e7af2f9c)
100%|████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]
Using custom data configuration default-16388deb41941231
Found cached dataset text (C:/Users/Theresa/.cache/huggingface/datasets/text/default-16388deb41941231/0.0.0/99cc88223027054f94ce0c7fd69d10eb172910fa0615671283a3c8e5e7af2f9c)
100%|████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "c:\Users\Theresa\OneDrive - KU Leuven\Documents\GitHub\simplify_dutch\main.py", line 286, in <module>
    tokenized_datasets = dataset.map(preprocess_function, batched=True)
NameError: name 'preprocess_function' is not defined
[31m╭─────────────────────────────── [39m[1mTraceback (most recent call last)[31m[22m ────────────────────────────────╮
[31m│[39m [33mc:\Users\Theresa\OneDrive - KU Leuven\Documents\GitHub\simplify_dutch\main.py[39m:[94m286[39m in [92m<module>[39m    [31m│
[31m│[39m                                                                                                  [31m│
[31m│[39m   283 │   wandb.watch(model, log=[33m"all"[39m)                                                          [31m│
[31m│[39m   284 │   dataset= get_train_data_txt(WIKILARGE_DATASET, [94m10[39m)                                     [31m│
[31m│[39m   285 │   [96mprint[39m(dataset[[33m'train'[39m][[94m3[39m])                                                             [31m│
[31m│[39m [31m❱ [39m286 │   tokenized_datasets = dataset.map(preprocess_function, batched=[94mTrue[39m)                    [31m│
[31m│[39m   287 │   [96mprint[39m(tokenized_datasets)                                                              [31m│
[31m│[39m   288 │   time.sleep([94m7[39m)                                                                          [31m│
[31m│[39m   289 │   tests= encoding_test(dataset)                                                          [31m│
[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯
[1mNameError: [22mname [32m'preprocess_function'[39m is not defined
Dataset({
    features: ['original', 'simple'],
    num_rows: 10
})
DatasetDict({
    train: Dataset({
        features: ['original', 'simple'],
        num_rows: 7
    })
    validation: Dataset({
        features: ['original', 'simple'],
        num_rows: 2
    })
    test: Dataset({
        features: ['original', 'simple'],
        num_rows: 1
    })
})
{'original': 'Er is manuscriptbewijs dat Austen tot in de periode 1809-11 aan deze stukken bleef werken, en dat haar nicht en neef, Anna en James Edward Austen, tot in 1814 verdere toevoegingen maakten.', 'simple': 'Er zijn aanwijzingen dat Austen later in zijn leven aan deze stukken bleef werken. Haar neef en nicht, James Edward en Anna Austen, hebben rond 1814 mogelijk nog meer aan haar werk toegevoegd.'}