{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Exploring several features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import re\n",
    "from sacremoses import MosesTokenizer\n",
    "import Levenshtein\n",
    "import spacy\n",
    "import nltk\n",
    "import pickle\n",
    "import urllib\n",
    "import os\n",
    "import tarfile\n",
    "import zipfile\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "# import paths\n",
    "from string import punctuation\n",
    "import matplotlib.pyplot as plt\n",
    "nltk.download('stopwords', quiet=True)\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "RESOURCES_DIR = Path('../resources')\n",
    "DATASETS_PATH = RESOURCES_DIR / \"datasets\"\n",
    "WORD_EMBEDDINGS_NAME = \"model\" #  \"glove.42B.300d\"  #  #'glove.6B.300d'\n",
    "DUMPS_DIR = RESOURCES_DIR / \"DUMPS\"\n",
    "import requests\n",
    "import gensim\n",
    "\n",
    "stopwords = set(stopwords.words(\"dutch\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternatives for Glove in Dutch: \n",
    "\n",
    "# https://fasttext.cc/docs/en/support.html#building-fasttext-python-module  voc size unknown, dims 300 installation failed because of wheel.\n",
    "# http://vectors.nlpl.eu/repository/#  voc size 2610658, dims 100\n",
    "# coosto https://github.com/coosto/dutch-word-embeddings  vocabulary 250479 dims 300 media data! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ControlDivisionByZero(numerator, denominator):\n",
    "    return numerator / denominator if denominator != 0 else 0\n",
    "\n",
    "\n",
    "class FeatureAbstract(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_ratio(self, kwargs):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def calculate_ratio(self, simple_text, original_text):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Feature(FeatureAbstract):\n",
    "\n",
    "    def __init__(self, split, target_ratio):\n",
    "        self.split = split\n",
    "        self.target_ratio = target_ratio\n",
    "\n",
    "    def get_ratio(self, kwargs):\n",
    "        if not 'original_text_preprocessed' in kwargs:\n",
    "            kwargs['original_text_preprocessed'] = \"\"\n",
    "\n",
    "        if self.split == \"train\":\n",
    "            simple_text = kwargs.get('simple_text')\n",
    "            original_text = kwargs.get('original_text')\n",
    "            result_ratio = self.calculate_ratio(simple_text, original_text)\n",
    "\n",
    "        elif self.split == \"valid\" or self.split == \"test\":\n",
    "            result_ratio = self.target_ratio\n",
    "        else:\n",
    "            raise ValueError(\"stage value not supported\")\n",
    "        kwargs['original_text_preprocessed'] += f'{self.name}_{result_ratio} '\n",
    "        return kwargs\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        class_name = self.__class__.__name__\n",
    "        name = \"\"\n",
    "        for word in re.findall('[A-Z][^A-Z]*', class_name):\n",
    "            if word: name += word[0]\n",
    "        if not name: name = class_name\n",
    "        return name\n",
    "\n",
    "\n",
    "class WordLengthRatio(Feature):\n",
    "\n",
    "    def __init__(self, stage, target_ratio):\n",
    "        super().__init__(stage, target_ratio)\n",
    "        if stage == \"train\":\n",
    "            # THIS IS A WORD TOKENIZER, we need one for dutch\n",
    "            # nl_core_news_sm spacy  spacy.nl_core_news_sm \n",
    "            # nltk.word_tokenize\n",
    "            self.tokenizer =  MosesTokenizer(lang='nl') #  nltk.word_tokenize(language='dutch')  # Moses Tokenizer for Dutch language\n",
    "\n",
    "    def calculate_ratio(self, simple_text, original_text):\n",
    "        return round(ControlDivisionByZero(\n",
    "            len(self.tokenizer.tokenize(simple_text)),\n",
    "            len(self.tokenizer.tokenize(original_text))), 2)\n",
    "\n",
    "\n",
    "class CharLengthRatio(Feature):\n",
    "\n",
    "    def __init__(self, stage, target_ratio):\n",
    "        super().__init__(stage, target_ratio)\n",
    "\n",
    "    def calculate_ratio(self, simple_text, original_text):\n",
    "        return round(ControlDivisionByZero(len(simple_text),\n",
    "            len(original_text)), 2)\n",
    "\n",
    "\n",
    "class LevenshteinRatio(Feature):\n",
    "\n",
    "    def __init__(self, stage, target_ratio):\n",
    "        super().__init__(stage, target_ratio)\n",
    "\n",
    "    def calculate_ratio(self, simple_text, original_text):\n",
    "        simple_text = word_tokenize(simple_text,language='dutch')\n",
    "        original_text = word_tokenize(original_text,language='dutch')\n",
    "        return round(Levenshtein.seqratio(original_text,\n",
    "                                       simple_text), 2)\n",
    "\n",
    "\n",
    "class DependencyTreeDepthRatio(Feature):\n",
    "\n",
    "    def __init__(self, stage, target_ratio):\n",
    "        super().__init__(stage, target_ratio)\n",
    "        if stage == \"train\":\n",
    "            self.nlp = self.get_spacy_model()\n",
    "\n",
    "    def get_spacy_model(self):\n",
    "\n",
    "        model = 'nl_core_news_sm'  # from spacy, Dutch pipeline optimized for CPU. Components: tok2vec, morphologizer, tagger, parser, lemmatizer (trainable_lemmatizer), senter, ner.\n",
    "        if not spacy.util.is_package(model):\n",
    "            spacy.cli.download(model)\n",
    "            spacy.cli.link(model, model, force=True, model_path=spacy.util.get_package_path(model))\n",
    "        return spacy.load(model)\n",
    "\n",
    "    def calculate_ratio(self, simple_text, original_text):\n",
    "\n",
    "        result_ratio = round(ControlDivisionByZero(\n",
    "            self.get_dependency_tree_depth(simple_text),\n",
    "            self.get_dependency_tree_depth(original_text)), 2)\n",
    "\n",
    "        return result_ratio\n",
    "\n",
    "    def get_dependency_tree_depth(self, sentence):\n",
    "\n",
    "        def get_subtree_depth(node):\n",
    "            if len(list(node.children)) == 0:\n",
    "                return 0\n",
    "            return 1 + max([get_subtree_depth(child) for child in node.children])\n",
    "\n",
    "        tree_depths = [get_subtree_depth(spacy_sentence.root) for spacy_sentence in self.nlp(sentence).sents]\n",
    "        if len(tree_depths) == 0:\n",
    "            return 0\n",
    "        return max(tree_depths)\n",
    "\n",
    "\n",
    "class WordRankRatio(Feature):\n",
    "    # single underscore = internally\n",
    "\n",
    "    def __init__(self, stage, target_ratio): # constructor of the class \n",
    "        super().__init__(stage, target_ratio)\n",
    "        if stage == \"train\":\n",
    "            self.tokenizer = MosesTokenizer(lang='nl')\n",
    "            self.word2rank = self._get_word2rank()\n",
    "            print('this is word2rank', self.word2rank)\n",
    "            print('length of word2rank', len(self.word2rank))\n",
    "            self.length_rank = len(self.word2rank) # hier length of the file! \n",
    "\n",
    "    def calculate_ratio(self, simple_text, original_text):\n",
    "\n",
    "        result_ratio = round(min(ControlDivisionByZero(self.get_lexical_complexity_score(simple_text),\n",
    "                                                       self.get_lexical_complexity_score(original_text)),\n",
    "                                 2), 2)\n",
    "\n",
    "        return result_ratio\n",
    "\n",
    "    def get_lexical_complexity_score(self, sentence, quantile_value=0.75):\n",
    "\n",
    "        words = self.tokenizer.tokenize(self._remove_stopwords(self._remove_punctuation(sentence)))\n",
    "        words = [word for word in words if word in self.word2rank]\n",
    "        if len(words) == 0:\n",
    "            return np.log(1 + self.length_rank)\n",
    "        return np.quantile([self._get_rank(word) for word in words], quantile_value)\n",
    "\n",
    "    def _remove_punctuation(self, text):\n",
    "        return ' '.join([word for word in self.tokenizer.tokenize(text) if not self._is_punctuation(word)])\n",
    "\n",
    "    def _remove_stopwords(self, text):\n",
    "        return ' '.join([w for w in self.tokenizer.tokenize(text) if w.lower() not in stopwords])\n",
    "\n",
    "    def _is_punctuation(self, word):\n",
    "        return ''.join([char for char in word if char not in punctuation]) == ''\n",
    "\n",
    "    def _get_rank(self, word):\n",
    "        rank = self.word2rank.get(word, self.length_rank)\n",
    "        return np.log(1 + rank)\n",
    "\n",
    "    def _get_word2rank(self, vocab_size=np.inf):\n",
    "        model_filepath = DUMPS_DIR / f\"{WORD_EMBEDDINGS_NAME}.pk\"\n",
    "        if model_filepath.exists():\n",
    "            with open(model_filepath, 'rb') as f:\n",
    "                model = pickle.load(f)\n",
    "            return model\n",
    "        \n",
    "        \n",
    "        else:\n",
    "            # print(\"Downloading glove ...\") # pretrained vectors\n",
    "            # self._download_glove(model_name='glove.6B', dest_dir=str(DUMPS_DIR))\n",
    "            # print(\"Preprocessing word2rank...\")\n",
    "            # DUMPS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "            # WORD_EMBEDDINGS_PATH = DUMPS_DIR / f'{WORD_EMBEDDINGS_NAME}.txt'\n",
    "            # lines_generator = self._yield_lines(WORD_EMBEDDINGS_PATH)\n",
    "            # word2rank = {}\n",
    "            # # next(lines_generator)\n",
    "            # print('vocab_size', vocab_size)\n",
    "            # for i, line in enumerate(lines_generator):\n",
    "            #     if i >= vocab_size: break\n",
    "            #     word = line.split(' ')[0]\n",
    "            #     print('word', word)\n",
    "            #     word2rank[word] = i\n",
    "            #     print('ranked word?', word2rank[word])\n",
    "\n",
    "            # pickle.dump(word2rank, open(model_filepath, 'wb'))\n",
    "            # txt_file = DUMPS_DIR / f'{WORD_EMBEDDINGS_NAME}.txt'\n",
    "            # zip_file = DUMPS_DIR / f'{WORD_EMBEDDINGS_NAME}.zip'\n",
    "            # # if txt_file.exists(): txt_file.unlink()\n",
    "            # if zip_file.exists(): zip_file.unlink()\n",
    "            # print(word2rank)\n",
    "            # return word2rank\n",
    "            \n",
    "            print(\"Downloading dutch embeddings ...\") # pretrained vectors\n",
    "            self._download_embeddings(model_name='coostco', dest_dir=str(DUMPS_DIR))\n",
    "            print(\"Preprocessing word2rank...\")\n",
    "            DUMPS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "            WORD_EMBEDDINGS_PATH = DUMPS_DIR / f'{WORD_EMBEDDINGS_NAME}.bin'\n",
    "            model = self._load_word_embeddings(WORD_EMBEDDINGS_PATH) # returns index_to_key\n",
    "            # store into file\n",
    "            lines_generator = self._yield_lines(model) # (WORD_EMBEDDINGS_PATH)\n",
    "            \n",
    "            word2rank = {}\n",
    "            # next(lines_generator)\n",
    "            print('vocab_size', vocab_size)\n",
    "            for i, line in enumerate(lines_generator):\n",
    "                if i >= vocab_size: break # its not vocab size any more but  # len(model.key_to_index)\n",
    "                word = line.split(',')[0]\n",
    "                # print('word', word)\n",
    "                word2rank[word] = i\n",
    "                # print('ranked word?', word2rank[word])\n",
    "                \n",
    "            pickle.dump(word2rank, open(model_filepath, 'wb'))\n",
    "            txt_file = DUMPS_DIR / f'{WORD_EMBEDDINGS_NAME}.txt'\n",
    "            zip_file = DUMPS_DIR / f'{WORD_EMBEDDINGS_NAME}.zip'\n",
    "            # if txt_file.exists(): txt_file.unlink()\n",
    "            # if zip_file.exists(): zip_file.unlink()\n",
    "            # print(word2rank)\n",
    "            return word2rank\n",
    "    \n",
    "    \n",
    "            #     WE_FILE = 'coosto.bin'\n",
    "        # wordembeddings_url = 'https://github.com/coosto/dutch-word-embeddings/releases/download/v1.0/model.bin'\n",
    "        # r = requests.get(wordembeddings_url)\n",
    "        # if r.status_code == 200:\n",
    "        #     with open(WE_FILE, 'wb') as wordembeddings_file:\n",
    "        #         wordembeddings_file.write(r.content)\n",
    "            \n",
    "        # https://github.com/tommasoc80/DALC/blob/2085fddf0fbac065c493b97079ae4ec27ddc7e00/v2.0/models/.ipynb_checkpoints/DALC_BiLSTM_offensive_binary-checkpoint.ipynb\n",
    "    \n",
    "                # store as TXT? \n",
    "                # download_word_embeddings()\n",
    "    \n",
    "    def _load_word_embeddings(self, filepath):\n",
    "        model = gensim.models.KeyedVectors.load_word2vec_format(filepath, binary=True) # '../resources/DUMPS/model.bin'\n",
    "        model_indexes = model.index_to_key\n",
    "        return model_indexes\n",
    "\n",
    "#  word_model = load_word_embeddings()\n",
    "    # def _vectorize_data(data, wm):\n",
    "    #     # turn the tokens into coosto vocab indices\n",
    "    #     # these will be converted to embeddings in the Embedding layer\n",
    "    #     vocab = wm.vocab\n",
    "    #     keys = list(vocab.keys())\n",
    "    #     final = []\n",
    "    #     for tweet in data:\n",
    "    #         final.append([keys.index(word) for word in tweet if vocab.get(word, None) is not None])\n",
    "    #     return final\n",
    "\n",
    "    def _download_glove(self, model_name, dest_dir): # pretrained rankings\n",
    "        url = ''\n",
    "        if model_name == 'glove.6B':\n",
    "            url = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
    "        elif model_name == 'glove.42B.300d':\n",
    "            url = 'http://nlp.stanford.edu/data/glove.42B.300d.zip'\n",
    "        elif model_name == 'glove.840B.300d':\n",
    "            url = 'http://nlp.stanford.edu/data/glove.840B.300d.zip'\n",
    "        elif model_name == 'glove.twitter.27B':\n",
    "            url = 'http://nlp.stanford.edu/data/glove.twitter.27B.zip',\n",
    "        else:\n",
    "            possible_values = ['glove.6B.300d', 'glove.42B.300d', 'glove.840B.300d', 'glove.twitter.27B']\n",
    "            raise ValueError('Unknown model_name. Possible values are {}'.format(possible_values))\n",
    "        file_path = self._download_url(url, dest_dir)\n",
    "        out_filepath = Path(file_path)\n",
    "        out_filepath = out_filepath.parent / f'{out_filepath.stem}.txt'\n",
    "        # print(out_filepath, out_filepath.exists())\n",
    "        if not out_filepath.exists():\n",
    "            print(\"Extracting: \", Path(file_path).name)\n",
    "            self._unzip(file_path, dest_dir)\n",
    "    \n",
    "    def _download_embeddings(self, model_name, dest_dir): # pretrained rankings\n",
    "        url = ''\n",
    "        if model_name == 'coostco':\n",
    "            url = 'https://github.com/coosto/dutch-word-embeddings/releases/download/v1.0/model.bin'\n",
    "\n",
    "        file_path = self._download_url(url, dest_dir)\n",
    "        out_filepath = Path(file_path)\n",
    "        out_filepath = out_filepath.parent / f'{out_filepath.stem}.txt'\n",
    "        # print(out_filepath, out_filepath.exists())\n",
    "        if not out_filepath.exists():\n",
    "            print(\"Extracting: \", Path(file_path).name)\n",
    "            self._unzip(file_path, dest_dir)\n",
    "\n",
    "    def _yield_lines(self, filepath):\n",
    "        filepath = Path(filepath)\n",
    "        with filepath.open('r', encoding=\"latin-1\") as f:\n",
    "            for line in f:\n",
    "                yield line.rstrip()\n",
    "\n",
    "    def _download_url(self, url, output_path):\n",
    "        name = url.split('/')[-1]\n",
    "        file_path = f'{output_path}/{name}'\n",
    "        if not Path(file_path).exists():\n",
    "            with tqdm(unit='B', unit_scale=True, leave=True, miniters=1,\n",
    "                      desc=name) as t:  # all optional kwargs\n",
    "                urllib.request.urlretrieve(url, filename=file_path, reporthook=self._download_report_hook(t), data=None)\n",
    "        return file_path\n",
    "\n",
    "    def _unzip(self, file_path, dest_dir=None):\n",
    "        if dest_dir is None:\n",
    "            dest_dir = os.path.dirname(file_path)\n",
    "        if file_path.endswith('.zip'):\n",
    "            with zipfile.ZipFile(file_path, \"r\") as zip_ref:\n",
    "                zip_ref.extractall(dest_dir)\n",
    "        elif file_path.endswith(\"tar.gz\") or file_path.endswith(\"tgz\"):\n",
    "            tar = tarfile.open(file_path, \"r:gz\")\n",
    "            tar.extractall(dest_dir)\n",
    "            tar.close()\n",
    "        elif file_path.endswith(\"tar\"):\n",
    "            tar = tarfile.open(file_path, \"r:\")\n",
    "            tar.extractall(dest_dir)\n",
    "            tar.close()\n",
    "\n",
    "    def _download_report_hook(self, t):\n",
    "        last_b = [0]\n",
    "\n",
    "        def inner(b=1, bsize=1, tsize=None):\n",
    "            if tsize is not None:\n",
    "                t.total = tsize\n",
    "            t.update((b - last_b[0]) * bsize)\n",
    "            last_b[0] = b\n",
    "\n",
    "        return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sentences_pair = {\"simple_text\": \"Dit is de complexe versie\", \"original_text\": \"Dit is de vereenvoudigte versie.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dutch embeddings ...\n",
      "Extracting:  model.bin\n",
      "Preprocessing word2rank...\n",
      "vocab_size inf\n"
     ]
    }
   ],
   "source": [
    "word_rank = WordRankRatio(\"train\", 0.8)\n",
    "sentences_pair = word_rank.get_ratio(sentences_pair)\n",
    "sentences_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../resources/DUMPS/model.bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m gensim\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mKeyedVectors\u001b[39m.\u001b[39;49mload_word2vec_format(\u001b[39m'\u001b[39;49m\u001b[39m../resources/DUMPS/model.bin\u001b[39;49m\u001b[39m'\u001b[39;49m, binary\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\Theresa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gensim\\models\\keyedvectors.py:1719\u001b[0m, in \u001b[0;36mKeyedVectors.load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[0;32m   1672\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m   1673\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_word2vec_format\u001b[39m(\n\u001b[0;32m   1674\u001b[0m         \u001b[39mcls\u001b[39m, fname, fvocab\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, binary\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf8\u001b[39m\u001b[39m'\u001b[39m, unicode_errors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1675\u001b[0m         limit\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, datatype\u001b[39m=\u001b[39mREAL, no_header\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   1676\u001b[0m     ):\n\u001b[0;32m   1677\u001b[0m     \u001b[39m\"\"\"Load KeyedVectors from a file produced by the original C word2vec-tool format.\u001b[39;00m\n\u001b[0;32m   1678\u001b[0m \n\u001b[0;32m   1679\u001b[0m \u001b[39m    Warnings\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1717\u001b[0m \n\u001b[0;32m   1718\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1719\u001b[0m     \u001b[39mreturn\u001b[39;00m _load_word2vec_format(\n\u001b[0;32m   1720\u001b[0m         \u001b[39mcls\u001b[39;49m, fname, fvocab\u001b[39m=\u001b[39;49mfvocab, binary\u001b[39m=\u001b[39;49mbinary, encoding\u001b[39m=\u001b[39;49mencoding, unicode_errors\u001b[39m=\u001b[39;49municode_errors,\n\u001b[0;32m   1721\u001b[0m         limit\u001b[39m=\u001b[39;49mlimit, datatype\u001b[39m=\u001b[39;49mdatatype, no_header\u001b[39m=\u001b[39;49mno_header,\n\u001b[0;32m   1722\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Theresa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gensim\\models\\keyedvectors.py:2048\u001b[0m, in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[0;32m   2045\u001b[0m             counts[word] \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(count)\n\u001b[0;32m   2047\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mloading projection weights from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, fname)\n\u001b[1;32m-> 2048\u001b[0m \u001b[39mwith\u001b[39;00m utils\u001b[39m.\u001b[39;49mopen(fname, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m fin:\n\u001b[0;32m   2049\u001b[0m     \u001b[39mif\u001b[39;00m no_header:\n\u001b[0;32m   2050\u001b[0m         \u001b[39m# deduce both vocab_size & vector_size from 1st pass over file\u001b[39;00m\n\u001b[0;32m   2051\u001b[0m         \u001b[39mif\u001b[39;00m binary:\n",
      "File \u001b[1;32mc:\\Users\\Theresa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\smart_open\\smart_open_lib.py:188\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, compression, transport_params)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[39mif\u001b[39;00m transport_params \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     transport_params \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 188\u001b[0m fobj \u001b[39m=\u001b[39m _shortcut_open(\n\u001b[0;32m    189\u001b[0m     uri,\n\u001b[0;32m    190\u001b[0m     mode,\n\u001b[0;32m    191\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m    192\u001b[0m     buffering\u001b[39m=\u001b[39;49mbuffering,\n\u001b[0;32m    193\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m    194\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    195\u001b[0m     newline\u001b[39m=\u001b[39;49mnewline,\n\u001b[0;32m    196\u001b[0m )\n\u001b[0;32m    197\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m     \u001b[39mreturn\u001b[39;00m fobj\n",
      "File \u001b[1;32mc:\\Users\\Theresa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\smart_open\\smart_open_lib.py:361\u001b[0m, in \u001b[0;36m_shortcut_open\u001b[1;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[39mif\u001b[39;00m errors \u001b[39mand\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m    359\u001b[0m     open_kwargs[\u001b[39m'\u001b[39m\u001b[39merrors\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m errors\n\u001b[1;32m--> 361\u001b[0m \u001b[39mreturn\u001b[39;00m _builtin_open(local_path, mode, buffering\u001b[39m=\u001b[39mbuffering, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mopen_kwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../resources/DUMPS/model.bin'"
     ]
    }
   ],
   "source": [
    "# model = gensim.models.KeyedVectors.load_word2vec_format('../resources/DUMPS/model.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'</s>': 0,\n",
       " 'de': 1,\n",
       " '<mention>': 2,\n",
       " '<url>': 3,\n",
       " 'een': 4,\n",
       " 'het': 5,\n",
       " 'en': 6,\n",
       " 'van': 7,\n",
       " 'in': 8,\n",
       " 'ik': 9,\n",
       " 'is': 10,\n",
       " 'op': 11,\n",
       " 'dat': 12,\n",
       " 'je': 13,\n",
       " 'voor': 14,\n",
       " 'met': 15,\n",
       " 'niet': 16,\n",
       " 'te': 17,\n",
       " 'zijn': 18,\n",
       " 'die': 19,\n",
       " 'maar': 20,\n",
       " 'ook': 21,\n",
       " 'er': 22,\n",
       " 'als': 23,\n",
       " 'om': 24,\n",
       " 'bij': 25,\n",
       " 'aan': 26,\n",
       " 'rt': 27,\n",
       " 'dan': 28,\n",
       " 'wat': 29,\n",
       " 'nog': 30,\n",
       " 'wel': 31,\n",
       " 'ze': 32,\n",
       " 'dit': 33,\n",
       " 'naar': 34,\n",
       " 'of': 35,\n",
       " 'we': 36,\n",
       " 'over': 37,\n",
       " 'heb': 38,\n",
       " 'al': 39,\n",
       " 'kan': 40,\n",
       " 'heeft': 41,\n",
       " 'zo': 42,\n",
       " 'uit': 43,\n",
       " 'mijn': 44,\n",
       " 'nu': 45,\n",
       " 'meer': 46,\n",
       " 'door': 47,\n",
       " 'was': 48,\n",
       " 'deze': 49,\n",
       " 'geen': 50,\n",
       " 'hij': 51,\n",
       " 'hebben': 52,\n",
       " 'weer': 53,\n",
       " 'ben': 54,\n",
       " 'moet': 55,\n",
       " 'goed': 56,\n",
       " 'wordt': 57,\n",
       " 'worden': 58,\n",
       " 'dus': 59,\n",
       " 'gaat': 60,\n",
       " 'toch': 61,\n",
       " 'veel': 62,\n",
       " 'echt': 63,\n",
       " 'gaan': 64,\n",
       " 'zou': 65,\n",
       " 'kunnen': 66,\n",
       " 'na': 67,\n",
       " 'daar': 68,\n",
       " 'wil': 69,\n",
       " 'hoe': 70,\n",
       " 'via': 71,\n",
       " 'hier': 72,\n",
       " 'vind': 73,\n",
       " 'mensen': 74,\n",
       " 'doen': 75,\n",
       " 'nieuwe': 76,\n",
       " 'waar': 77,\n",
       " 'tot': 78,\n",
       " 'jaar': 79,\n",
       " 'eens': 80,\n",
       " 'mij': 81,\n",
       " 'haar': 82,\n",
       " 'heel': 83,\n",
       " 'gewoon': 84,\n",
       " 'me': 85,\n",
       " 'alleen': 86,\n",
       " 'had': 87,\n",
       " 'maken': 88,\n",
       " 'mee': 89,\n",
       " 'tegen': 90,\n",
       " 'hun': 91,\n",
       " 'jij': 92,\n",
       " 'komt': 93,\n",
       " 'even': 94,\n",
       " '1': 95,\n",
       " 'wij': 96,\n",
       " 'ons': 97,\n",
       " 'ja': 98,\n",
       " 'zal': 99,\n",
       " 'iets': 100,\n",
       " 'altijd': 101,\n",
       " 'moeten': 102,\n",
       " '2': 103,\n",
       " 'onze': 104,\n",
       " 'u': 105,\n",
       " 'vandaag': 106,\n",
       " 'zich': 107,\n",
       " 'zelf': 108,\n",
       " 'staat': 109,\n",
       " 'ga': 110,\n",
       " 'andere': 111,\n",
       " 'zien': 112,\n",
       " 'omdat': 113,\n",
       " 'weet': 114,\n",
       " 'komen': 115,\n",
       " 'tijd': 116,\n",
       " 'hem': 117,\n",
       " 'alle': 118,\n",
       " 'jullie': 119,\n",
       " 'net': 120,\n",
       " 'eerste': 121,\n",
       " 'want': 122,\n",
       " 'leuk': 123,\n",
       " 'zit': 124,\n",
       " 'alles': 125,\n",
       " 'af': 126,\n",
       " 'man': 127,\n",
       " 'werd': 128,\n",
       " 'denk': 129,\n",
       " 'twee': 130,\n",
       " 'laat': 131,\n",
       " 'mag': 132,\n",
       " 'onder': 133,\n",
       " 'terug': 134,\n",
       " 'dag': 135,\n",
       " 'zie': 136,\n",
       " 'nederland': 137,\n",
       " 'nooit': 138,\n",
       " 'wie': 139,\n",
       " 'zon': 140,\n",
       " 'weg': 141,\n",
       " 'beter': 142,\n",
       " 'zeker': 143,\n",
       " 'willen': 144,\n",
       " 'waarom': 145,\n",
       " 'keer': 146,\n",
       " 'iemand': 147,\n",
       " 'hebt': 148,\n",
       " '3': 149,\n",
       " 'zoals': 150,\n",
       " 'mooi': 151,\n",
       " 'lekker': 152,\n",
       " 'eigen': 153,\n",
       " 'anders': 154,\n",
       " 'staan': 155,\n",
       " 'doet': 156,\n",
       " 'tijdens': 157,\n",
       " 'toen': 158,\n",
       " 'mooie': 159,\n",
       " 'grote': 160,\n",
       " 't': 161,\n",
       " 'kijken': 162,\n",
       " 'zonder': 163,\n",
       " 'allemaal': 164,\n",
       " 'misschien': 165,\n",
       " 'iedereen': 166,\n",
       " 'zij': 167,\n",
       " 'laten': 168,\n",
       " 'helemaal': 169,\n",
       " 'krijgen': 170,\n",
       " 'verder': 171,\n",
       " 'natuurlijk': 172,\n",
       " 'binnen': 173,\n",
       " 'leven': 174,\n",
       " 'maakt': 175,\n",
       " 'graag': 176,\n",
       " 'weten': 177,\n",
       " 'goede': 178,\n",
       " '#nieuwstwitter': 179,\n",
       " 'hoor': 180,\n",
       " 'laatste': 181,\n",
       " 'zeggen': 182,\n",
       " 'zegt': 183,\n",
       " 'snel': 184,\n",
       " 'bent': 185,\n",
       " 'toe': 186,\n",
       " 'nou': 187,\n",
       " 'kinderen': 188,\n",
       " 'waren': 189,\n",
       " 'erg': 190,\n",
       " 'vinden': 191,\n",
       " 'werk': 192,\n",
       " 'jou': 193,\n",
       " 'video': 194,\n",
       " 'krijgt': 195,\n",
       " 'samen': 196,\n",
       " 'elkaar': 197,\n",
       " 'nodig': 198,\n",
       " 'video_leuk': 199,\n",
       " 'hele': 200,\n",
       " 'tussen': 201,\n",
       " 'vanaf': 202,\n",
       " 'zitten': 203,\n",
       " 'beetje': 204,\n",
       " 'minder': 205,\n",
       " 'doe': 206,\n",
       " 'niets': 207,\n",
       " '4': 208,\n",
       " 'geven': 209,\n",
       " 'geld': 210,\n",
       " 'wanneer': 211,\n",
       " 'eigenlijk': 212,\n",
       " 'kijk': 213,\n",
       " 'vaak': 214,\n",
       " 'beste': 215,\n",
       " 'vraag': 216,\n",
       " 'kom': 217,\n",
       " 'eerst': 218,\n",
       " 'nee': 219,\n",
       " 'week': 220,\n",
       " '10': 221,\n",
       " '5': 222,\n",
       " 'vooral': 223,\n",
       " 'bijna': 224,\n",
       " 'morgen': 225,\n",
       " 'zelfs': 226,\n",
       " 'blijft': 227,\n",
       " 'huis': 228,\n",
       " 'uur': 229,\n",
       " 'mn': 230,\n",
       " 'werken': 231,\n",
       " 'lang': 232,\n",
       " 'kunt': 233,\n",
       " 'volgens': 234,\n",
       " 'kun': 235,\n",
       " 'achter': 236,\n",
       " 'best': 237,\n",
       " 'niks': 238,\n",
       " 'gedaan': 239,\n",
       " 'hoop': 240,\n",
       " 'blijven': 241,\n",
       " 'gemaakt': 242,\n",
       " 'foto': 243,\n",
       " 'ging': 244,\n",
       " 'gezien': 245,\n",
       " 'geeft': 246,\n",
       " 'ziet': 247,\n",
       " 'auto': 248,\n",
       " 'houden': 249,\n",
       " 'geweest': 250,\n",
       " 'vrouw': 251,\n",
       " '2017': 252,\n",
       " 'nog_steeds': 253,\n",
       " 'kon': 254,\n",
       " 'mogelijk': 255,\n",
       " 'genoeg': 256,\n",
       " 'he': 257,\n",
       " 'kwam': 258,\n",
       " 'uw': 259,\n",
       " 'jouw': 260,\n",
       " 'politie': 261,\n",
       " 'spelen': 262,\n",
       " 'ajax': 263,\n",
       " 'vragen': 264,\n",
       " 'welke': 265,\n",
       " 'zeg': 266,\n",
       " 'soms': 267,\n",
       " 'nemen': 268,\n",
       " 'pas': 269,\n",
       " 'nieuws': 270,\n",
       " 'gelukkig': 271,\n",
       " 'terwijl': 272,\n",
       " 'nieuw': 273,\n",
       " 'denken': 274,\n",
       " 'amsterdam': 275,\n",
       " 'krijg': 276,\n",
       " 'lees': 277,\n",
       " 'thuis': 278,\n",
       " 'open': 279,\n",
       " 'zullen': 280,\n",
       " 'drie': 281,\n",
       " 'blij': 282,\n",
       " 'ligt': 283,\n",
       " 'aantal': 284,\n",
       " 'lijkt': 285,\n",
       " 'hadden': 286,\n",
       " 'helaas': 287,\n",
       " 'vast': 288,\n",
       " 'eten': 289,\n",
       " 'haha': 290,\n",
       " 'gehad': 291,\n",
       " 'weinig': 292,\n",
       " 'moment': 293,\n",
       " 'werkt': 294,\n",
       " 'klaar': 295,\n",
       " 'eerder': 296,\n",
       " 'inderdaad': 297,\n",
       " '12': 298,\n",
       " 'dagen': 299,\n",
       " 'mogen': 300,\n",
       " 'gelijk': 301,\n",
       " 'ooit': 302,\n",
       " 'plaats': 303,\n",
       " 'leuke': 304,\n",
       " 'steeds': 305,\n",
       " 'vanavond': 306,\n",
       " 'dingen': 307,\n",
       " 'daarom': 308,\n",
       " 'buiten': 309,\n",
       " 'kans': 310,\n",
       " 'juist': 311,\n",
       " 'vindt': 312,\n",
       " 'land': 313,\n",
       " 'nl': 314,\n",
       " 'gebruik': 315,\n",
       " 'groot': 316,\n",
       " 'word': 317,\n",
       " 'rond': 318,\n",
       " 'extra': 319,\n",
       " 'moest': 320,\n",
       " '6': 321,\n",
       " 'probleem': 322,\n",
       " 'artikel': 323,\n",
       " 'men': 324,\n",
       " 'zetten': 325,\n",
       " 'zin': 326,\n",
       " 'vrouwen': 327,\n",
       " 'halen': 328,\n",
       " 'ander': 329,\n",
       " 'vond': 330,\n",
       " 'fotos': 331,\n",
       " 'zeer': 332,\n",
       " '20': 333,\n",
       " 'vanuit': 334,\n",
       " 'wereld': 335,\n",
       " 'zondag': 336,\n",
       " 'duidelijk': 337,\n",
       " 'lezen': 338,\n",
       " 'zouden': 339,\n",
       " 'gemeente': 340,\n",
       " 'paar': 341,\n",
       " 'zoveel': 342,\n",
       " 'enige': 343,\n",
       " 'fijn': 344,\n",
       " 'later': 345,\n",
       " 'dacht': 346,\n",
       " 'zaterdag': 347,\n",
       " 'naam': 348,\n",
       " 'daarna': 349,\n",
       " 'vrij': 350,\n",
       " 'naast': 351,\n",
       " 'onderzoek': 352,\n",
       " 'wedstrijd': 353,\n",
       " 'prima': 354,\n",
       " 'deel': 355,\n",
       " 'school': 356,\n",
       " 'verhaal': 357,\n",
       " 'precies': 358,\n",
       " 'zei': 359,\n",
       " 'wachten': 360,\n",
       " 'lopen': 361,\n",
       " 'maak': 362,\n",
       " 'gebruiken': 363,\n",
       " 'seizoen': 364,\n",
       " 'bekend': 365,\n",
       " 'boek': 366,\n",
       " 'begin': 367,\n",
       " '#actueel': 368,\n",
       " 'start': 369,\n",
       " 'houdt': 370,\n",
       " 'kleine': 371,\n",
       " 'zet': 372,\n",
       " 'niemand': 373,\n",
       " 'valt': 374,\n",
       " 'bijvoorbeeld': 375,\n",
       " 'horen': 376,\n",
       " 'oude': 377,\n",
       " 'kreeg': 378,\n",
       " 'mannen': 379,\n",
       " 'nederlandse': 380,\n",
       " 'online': 381,\n",
       " 'wilde': 382,\n",
       " 'gratis': 383,\n",
       " 'zat': 384,\n",
       " 'n': 385,\n",
       " 'moeder': 386,\n",
       " 'hard': 387,\n",
       " 'helpen': 388,\n",
       " 'zodat': 389,\n",
       " 'dank': 390,\n",
       " 'per': 391,\n",
       " 'gisteren': 392,\n",
       " 'a': 393,\n",
       " '7': 394,\n",
       " 'feyenoord': 395,\n",
       " 'vol': 396,\n",
       " 'wilt': 397,\n",
       " 'kind': 398,\n",
       " 'zag': 399,\n",
       " 'stad': 400,\n",
       " '8': 401,\n",
       " 'inmiddels': 402,\n",
       " 'top': 403,\n",
       " 'namelijk': 404,\n",
       " 'rijden': 405,\n",
       " 'team': 406,\n",
       " 'echter': 407,\n",
       " 'tweede': 408,\n",
       " 'bezig': 409,\n",
       " 'trump': 410,\n",
       " 'hand': 411,\n",
       " 'elke': 412,\n",
       " 'zn': 413,\n",
       " 'kopen': 414,\n",
       " 'sinds': 415,\n",
       " 'ie': 416,\n",
       " 'bedrijf': 417,\n",
       " 'meteen': 418,\n",
       " 'jaren': 419,\n",
       " 'idee': 420,\n",
       " 'volgende': 421,\n",
       " 'rotterdam': 422,\n",
       " 'club': 423,\n",
       " 'jammer': 424,\n",
       " 'straks': 425,\n",
       " 'twitter': 426,\n",
       " 'volgens_mij': 427,\n",
       " 'afspeellijst': 428,\n",
       " 'gebruikt': 429,\n",
       " 'zoeken': 430,\n",
       " 'bedankt': 431,\n",
       " 'boven': 432,\n",
       " 'ouders': 433,\n",
       " 'opnieuw': 434,\n",
       " 'groep': 435,\n",
       " 'video_toegevoegd_aan': 436,\n",
       " 'langs': 437,\n",
       " 'begint': 438,\n",
       " 'super': 439,\n",
       " 'beginnen': 440,\n",
       " 'ff': 441,\n",
       " 'betalen': 442,\n",
       " 'stond': 443,\n",
       " 'echte': 444,\n",
       " 'weekend': 445,\n",
       " 'm': 446,\n",
       " 'water': 447,\n",
       " 'neemt': 448,\n",
       " 'vrijdag': 449,\n",
       " 'liggen': 450,\n",
       " 'druk': 451,\n",
       " 'waarschijnlijk': 452,\n",
       " 'zorgen': 453,\n",
       " 'stuk': 454,\n",
       " 'zorg': 455,\n",
       " 'vakantie': 456,\n",
       " 'wist': 457,\n",
       " 'eindelijk': 458,\n",
       " 'manier': 459,\n",
       " 'snap': 460,\n",
       " 'verwacht': 461,\n",
       " 'speelt': 462,\n",
       " 'live': 463,\n",
       " '15': 464,\n",
       " 'slecht': 465,\n",
       " 'direct': 466,\n",
       " 'heerlijk': 467,\n",
       " 'hou': 468,\n",
       " 'belangrijk': 469,\n",
       " 'moeilijk': 470,\n",
       " 'rest': 471,\n",
       " 'werden': 472,\n",
       " '#nieuws': 473,\n",
       " 'meisje': 474,\n",
       " 'uiteindelijk': 475,\n",
       " 'geef': 476,\n",
       " 'vier': 477,\n",
       " 'neem': 478,\n",
       " 'leren': 479,\n",
       " 'problemen': 480,\n",
       " '#voetbal': 481,\n",
       " 'prijs': 482,\n",
       " 'normaal': 483,\n",
       " 'totaal': 484,\n",
       " 'toekomst': 485,\n",
       " 'heen': 486,\n",
       " 'hoofd': 487,\n",
       " 'koop': 488,\n",
       " 'bericht': 489,\n",
       " 'europa': 490,\n",
       " 'geworden': 491,\n",
       " 'dood': 492,\n",
       " 'actie': 493,\n",
       " 'mocht': 494,\n",
       " '#vacature': 495,\n",
       " '30': 496,\n",
       " 'proberen': 497,\n",
       " 'loopt': 498,\n",
       " 'gevonden': 499,\n",
       " 'winnen': 500,\n",
       " 'aandacht': 501,\n",
       " 'maandag': 502,\n",
       " 'klopt': 503,\n",
       " 'zoek_naar': 504,\n",
       " 'vrienden': 505,\n",
       " 'gevoel': 506,\n",
       " 'nummer': 507,\n",
       " 'denkt': 508,\n",
       " 'plek': 509,\n",
       " 'vroeg': 510,\n",
       " 'volgen': 511,\n",
       " 'reactie': 512,\n",
       " 'partij': 513,\n",
       " 'genieten': 514,\n",
       " 'tv': 515,\n",
       " 'soort': 516,\n",
       " 'spelers': 517,\n",
       " 'reden': 518,\n",
       " 'liever': 519,\n",
       " 'mis': 520,\n",
       " 'da': 521,\n",
       " 'geloof': 522,\n",
       " 'gek': 523,\n",
       " 'deed': 524,\n",
       " 'brengen': 525,\n",
       " 'vs': 526,\n",
       " 'trouwens': 527,\n",
       " 'utrecht': 528,\n",
       " 'avond': 529,\n",
       " '100': 530,\n",
       " 'waardoor': 531,\n",
       " 'blijkt': 532,\n",
       " 'ervaring': 533,\n",
       " 'programma': 534,\n",
       " 'meeste': 535,\n",
       " 'antwoord': 536,\n",
       " 'vanwege': 537,\n",
       " 'vervolgens': 538,\n",
       " 'website': 539,\n",
       " 'x': 540,\n",
       " 'waarin': 541,\n",
       " 'muziek': 542,\n",
       " 'richting': 543,\n",
       " 'bedrijven': 544,\n",
       " 'anderen': 545,\n",
       " 'zichzelf': 546,\n",
       " 'jezelf': 547,\n",
       " 'ergens': 548,\n",
       " 'delen': 549,\n",
       " '2016': 550,\n",
       " 'overigens': 551,\n",
       " 'euro': 552,\n",
       " 'land_nederland_geslacht_vrouw': 553,\n",
       " '25': 554,\n",
       " '11': 555,\n",
       " 'basis': 556,\n",
       " 'stemmen': 557,\n",
       " 'dezelfde': 558,\n",
       " 'bestaat': 559,\n",
       " 'waarbij': 560,\n",
       " 'vader': 561,\n",
       " 'psv': 562,\n",
       " 'beeld': 563,\n",
       " 'hoeveel': 564,\n",
       " 'kosten': 565,\n",
       " 'gesprek': 566,\n",
       " 'daarnaast': 567,\n",
       " 'geval': 568,\n",
       " 'maand': 569,\n",
       " 'familie': 570,\n",
       " 'jongens': 571,\n",
       " 'praten': 572,\n",
       " 'ken': 573,\n",
       " 'prachtige': 574,\n",
       " 'begonnen': 575,\n",
       " 'eu': 576,\n",
       " 'hen': 577,\n",
       " 'langer': 578,\n",
       " 'd': 579,\n",
       " '#nieuws_#nederland': 580,\n",
       " 'geweldig': 581,\n",
       " 'alsof': 582,\n",
       " 'hoeft': 583,\n",
       " '>': 584,\n",
       " 'hopelijk': 585,\n",
       " 'punt': 586,\n",
       " '22': 587,\n",
       " 'film': 588,\n",
       " 'woord': 589,\n",
       " 'vorig_jaar': 590,\n",
       " 'einde': 591,\n",
       " 'donderdag': 592,\n",
       " 'maakte': 593,\n",
       " 'zowel': 594,\n",
       " 'kiezen': 595,\n",
       " 'hetzelfde': 596,\n",
       " 'trots': 597,\n",
       " 'app': 598,\n",
       " 'ogen': 599,\n",
       " 'vergeten': 600,\n",
       " 'bed': 601,\n",
       " 'ver': 602,\n",
       " 'gekregen': 603,\n",
       " '9': 604,\n",
       " 'slapen': 605,\n",
       " 'lijkt_me': 606,\n",
       " 'woensdag': 607,\n",
       " 'verschillende': 608,\n",
       " 'succes': 609,\n",
       " 'vriend': 610,\n",
       " 'jonge': 611,\n",
       " 'makkelijk': 612,\n",
       " 'tweet': 613,\n",
       " 'stellen': 614,\n",
       " 'ruimte': 615,\n",
       " 'politiek': 616,\n",
       " 'enkel': 617,\n",
       " 'voorbij': 618,\n",
       " 'vijf': 619,\n",
       " 'hahaha': 620,\n",
       " 'jong': 621,\n",
       " 'the': 622,\n",
       " 'internet': 623,\n",
       " 'liefde': 624,\n",
       " 'belgie': 625,\n",
       " 'oh': 626,\n",
       " 'grootste': 627,\n",
       " 'mens': 628,\n",
       " 'daarmee': 629,\n",
       " 'slechts': 630,\n",
       " 'plaatsen': 631,\n",
       " 'gezegd': 632,\n",
       " 'alweer': 633,\n",
       " 'los': 634,\n",
       " 'stoppen': 635,\n",
       " 'sorry': 636,\n",
       " 'recht': 637,\n",
       " 'gebeuren': 638,\n",
       " '50': 639,\n",
       " 'bank': 640,\n",
       " 'plan': 641,\n",
       " 'hoort': 642,\n",
       " 'persoon': 643,\n",
       " 'mening': 644,\n",
       " 'woorden': 645,\n",
       " 'heel_erg': 646,\n",
       " 'ondanks': 647,\n",
       " 'links': 648,\n",
       " 'zoek': 649,\n",
       " 'den_haag': 650,\n",
       " 'facebook': 651,\n",
       " 'bang': 652,\n",
       " 'punten': 653,\n",
       " 'voordat': 654,\n",
       " 'betekent': 655,\n",
       " 'afgelopen': 656,\n",
       " 'gebeurt': 657,\n",
       " 'telefoon': 658,\n",
       " 'ontvangen': 659,\n",
       " 'kamer': 660,\n",
       " 'last': 661,\n",
       " 'idd': 662,\n",
       " 'terecht': 663,\n",
       " 'doel': 664,\n",
       " 'trein': 665,\n",
       " 'bekijk': 666,\n",
       " 'bezoek': 667,\n",
       " 'erbij': 668,\n",
       " 'buurt': 669,\n",
       " 'wonen': 670,\n",
       " 'stem': 671,\n",
       " 'fout': 672,\n",
       " 'zaken': 673,\n",
       " 'informatie': 674,\n",
       " 'rust': 675,\n",
       " 'contact': 676,\n",
       " 'zomer': 677,\n",
       " 'vroeger': 678,\n",
       " 'keuze': 679,\n",
       " 'ineens': 680,\n",
       " 'v': 681,\n",
       " 'prachtig': 682,\n",
       " 'blijkbaar': 683,\n",
       " 'klein': 684,\n",
       " 'oud': 685,\n",
       " 'woning': 686,\n",
       " 'ipv': 687,\n",
       " 'etc': 688,\n",
       " 'ieder_geval': 689,\n",
       " 'feit': 690,\n",
       " 'vertellen': 691,\n",
       " 'nadat': 692,\n",
       " 'volledig': 693,\n",
       " 'burgemeester': 694,\n",
       " 'kut': 695,\n",
       " 'neuken': 696,\n",
       " 'oplossing': 697,\n",
       " '@': 698,\n",
       " 'stel': 699,\n",
       " 'ongeveer': 700,\n",
       " 'hoog': 701,\n",
       " 'site': 702,\n",
       " 'dit_soort': 703,\n",
       " 'hart': 704,\n",
       " 'winkel': 705,\n",
       " 'overal': 706,\n",
       " 'oke': 707,\n",
       " 'kennis': 708,\n",
       " 'dinsdag': 709,\n",
       " 'uiteraard': 710,\n",
       " 'tips': 711,\n",
       " 'straat': 712,\n",
       " 'aanwezig': 713,\n",
       " '2018': 714,\n",
       " 'markt': 715,\n",
       " 'vvd': 716,\n",
       " 'ruim': 717,\n",
       " '13': 718,\n",
       " 'blijf': 719,\n",
       " 'wellicht': 720,\n",
       " 'daarbij': 721,\n",
       " 'binnenkort': 722,\n",
       " 'oa': 723,\n",
       " 'noemen': 724,\n",
       " 'schrijven': 725,\n",
       " 'aldus': 726,\n",
       " 'pakken': 727,\n",
       " 'enorm': 728,\n",
       " 'blog': 729,\n",
       " 'sommige': 730,\n",
       " 'vriendin': 731,\n",
       " 'mezelf': 732,\n",
       " 'jongen': 733,\n",
       " '18': 734,\n",
       " 'grond': 735,\n",
       " 'handen': 736,\n",
       " 'meestal': 737,\n",
       " 'vertrouwen': 738,\n",
       " 'kost': 739,\n",
       " 'bijzonder': 740,\n",
       " 'gekomen': 741,\n",
       " 'benieuwd': 742,\n",
       " 'groningen': 743,\n",
       " 'vallen': 744,\n",
       " 'vraagt': 745,\n",
       " 'fiets': 746,\n",
       " 'betreft': 747,\n",
       " 'omgeving': 748,\n",
       " 'beschikbaar': 749,\n",
       " 'kort': 750,\n",
       " 'dochter': 751,\n",
       " 'sowieso': 752,\n",
       " 'licht': 753,\n",
       " 'gegaan': 754,\n",
       " 'welkom': 755,\n",
       " 'gegeven': 756,\n",
       " 'tegenwoordig': 757,\n",
       " 'gezellig': 758,\n",
       " 'baan': 759,\n",
       " 'beide': 760,\n",
       " 'duitsland': 761,\n",
       " 'miljoen': 762,\n",
       " 'helpt': 763,\n",
       " 'sterk': 764,\n",
       " 'hond': 765,\n",
       " 'hopen': 766,\n",
       " 'gebied': 767,\n",
       " 'vanmiddag': 768,\n",
       " 'bus': 769,\n",
       " 'voelt': 770,\n",
       " 'media': 771,\n",
       " 'lastig': 772,\n",
       " 'raad': 773,\n",
       " 'vele': 774,\n",
       " 'sturen': 775,\n",
       " 'nie': 776,\n",
       " 'wakker': 777,\n",
       " 'kijkt': 778,\n",
       " '40': 779,\n",
       " 'maanden': 780,\n",
       " 'das': 781,\n",
       " 'organisatie': 782,\n",
       " 'o': 783,\n",
       " 'update': 784,\n",
       " 'vorm': 785,\n",
       " 'nacht': 786,\n",
       " 'link': 787,\n",
       " 'slag': 788,\n",
       " 'gezicht': 789,\n",
       " 'overheid': 790,\n",
       " 'verschil': 791,\n",
       " '14': 792,\n",
       " 'vaker': 793,\n",
       " 'boeken': 794,\n",
       " '16': 795,\n",
       " 'stelt': 796,\n",
       " 'voorkomen': 797,\n",
       " 'vd': 798,\n",
       " 'volg': 799,\n",
       " 'huidige': 800,\n",
       " 'deur': 801,\n",
       " 'serieus': 802,\n",
       " 'wint': 803,\n",
       " 'lol': 804,\n",
       " 'daarvoor': 805,\n",
       " 'kant': 806,\n",
       " 'b': 807,\n",
       " 'kent': 808,\n",
       " 'p': 809,\n",
       " 'ofzo': 810,\n",
       " 'jaar_geleden': 811,\n",
       " 'enkele': 812,\n",
       " 'klanten': 813,\n",
       " 'stap': 814,\n",
       " 'hulp': 815,\n",
       " 'god': 816,\n",
       " 'zoon': 817,\n",
       " 'rutte': 818,\n",
       " 'ding': 819,\n",
       " 'klinkt': 820,\n",
       " 'zoekt': 821,\n",
       " 'rustig': 822,\n",
       " 'project': 823,\n",
       " 'gekocht': 824,\n",
       " 'jan': 825,\n",
       " 'dicht': 826,\n",
       " 'islam': 827,\n",
       " 'ene': 828,\n",
       " 'leggen': 829,\n",
       " 'vertelt': 830,\n",
       " 'kwamen': 831,\n",
       " 'probeer': 832,\n",
       " 'spel': 833,\n",
       " 'voetbal': 834,\n",
       " 'kwijt': 835,\n",
       " 'begon': 836,\n",
       " 'lief': 837,\n",
       " 'jongeren': 838,\n",
       " 'wacht': 839,\n",
       " 'konden': 840,\n",
       " 'stuur': 841,\n",
       " 'winst': 842,\n",
       " 'regio': 843,\n",
       " 'gezet': 844,\n",
       " 'moeite': 845,\n",
       " 'leden': 846,\n",
       " 'heet': 847,\n",
       " 'begrijp': 848,\n",
       " 'aangezien': 849,\n",
       " 'geniet': 850,\n",
       " 'gaf': 851,\n",
       " 'pvv': 852,\n",
       " 'trekken': 853,\n",
       " 'merk': 854,\n",
       " 'kop': 855,\n",
       " 'hallo': 856,\n",
       " 'spreken': 857,\n",
       " 'bedoel': 858,\n",
       " 'derde': 859,\n",
       " 'pijn': 860,\n",
       " 'college': 861,\n",
       " 'gelezen_via': 862,\n",
       " 'lichaam': 863,\n",
       " 'gingen': 864,\n",
       " 'momenteel': 865,\n",
       " 'speler': 866,\n",
       " 'kwaliteit': 867,\n",
       " 'brand': 868,\n",
       " 'liefst': 869,\n",
       " '21': 870,\n",
       " 'moslims': 871,\n",
       " 'zaak': 872,\n",
       " 'gehoord': 873,\n",
       " 'ge': 874,\n",
       " 'weken': 875,\n",
       " 'verkopen': 876,\n",
       " 'systeem': 877,\n",
       " 'samenwerking': 878,\n",
       " 'dames': 879,\n",
       " 'wet': 880,\n",
       " 'veranderen': 881,\n",
       " 'collegas': 882,\n",
       " 'waarvan': 883,\n",
       " 'k': 884,\n",
       " 'past': 885,\n",
       " 'voorbeeld': 886,\n",
       " 'situatie': 887,\n",
       " 'autos': 888,\n",
       " 'bovendien': 889,\n",
       " 'brengt': 890,\n",
       " 'meerdere': 891,\n",
       " 'meisjes': 892,\n",
       " 'dankzij': 893,\n",
       " 'ondertussen': 894,\n",
       " 'houd': 895,\n",
       " 'producten': 896,\n",
       " 'oranje': 897,\n",
       " 'info': 898,\n",
       " 'turkije': 899,\n",
       " 'zomaar': 900,\n",
       " 'qua': 901,\n",
       " 'filmpje': 902,\n",
       " 'rol': 903,\n",
       " 'plannen': 904,\n",
       " 'daardoor': 905,\n",
       " 'groter': 906,\n",
       " 'teveel': 907,\n",
       " 'sta': 908,\n",
       " 'tip': 909,\n",
       " 'tja': 910,\n",
       " 'locatie': 911,\n",
       " 'nergens': 912,\n",
       " 'advies': 913,\n",
       " 'minister': 914,\n",
       " 'gezocht': 915,\n",
       " 'veilig': 916,\n",
       " 'serie': 917,\n",
       " 'gebeurd': 918,\n",
       " 'september': 919,\n",
       " 'elke_dag': 920,\n",
       " 'gefeliciteerd': 921,\n",
       " 'rechter': 922,\n",
       " 'bouwen': 923,\n",
       " 'partijen': 924,\n",
       " 'lid': 925,\n",
       " 'betaald': 926,\n",
       " '23': 927,\n",
       " 'bv': 928,\n",
       " 'wilders': 929,\n",
       " 'ieder': 930,\n",
       " 'melding': 931,\n",
       " 'volgende_week': 932,\n",
       " 'voel': 933,\n",
       " 'gelezen': 934,\n",
       " 'max': 935,\n",
       " 'juiste': 936,\n",
       " 'voelen': 937,\n",
       " 'resultaat': 938,\n",
       " 'wedstrijden': 939,\n",
       " 'bepaalde': 940,\n",
       " 'centrum': 941,\n",
       " 'zoekt_manmeer_over': 942,\n",
       " 'zorgt': 943,\n",
       " 'bleek': 944,\n",
       " 'bellen': 945,\n",
       " 'tafel': 946,\n",
       " 'stil': 947,\n",
       " 'kleur': 948,\n",
       " 'flink': 949,\n",
       " 'eerlijk': 950,\n",
       " 'omg': 951,\n",
       " 'zolang': 952,\n",
       " 'stukje': 953,\n",
       " 'volgt': 954,\n",
       " 'bieden': 955,\n",
       " 'lachen': 956,\n",
       " 'regelmatig': 957,\n",
       " '#voetbalnt': 958,\n",
       " 'eindhoven': 959,\n",
       " 'sport': 960,\n",
       " 'liet': 961,\n",
       " 'zwaar': 962,\n",
       " '17': 963,\n",
       " 's': 964,\n",
       " 'haalt': 965,\n",
       " 'bal': 966,\n",
       " 'reacties': 967,\n",
       " 'belang': 968,\n",
       " 'dieren': 969,\n",
       " 'eind': 970,\n",
       " 'voldoende': 971,\n",
       " 'gewonnen': 972,\n",
       " 'iedere': 973,\n",
       " 'raar': 974,\n",
       " 'hoewel': 975,\n",
       " 'titel': 976,\n",
       " 'ok': 977,\n",
       " 'medewerkers': 978,\n",
       " 'besluit': 979,\n",
       " 'reageren': 980,\n",
       " 'bedoeld': 981,\n",
       " 'nederlanders': 982,\n",
       " 'rij': 983,\n",
       " 'kapot': 984,\n",
       " 'niveau': 985,\n",
       " 'onderwijs': 986,\n",
       " 'elk': 987,\n",
       " 'kennen': 988,\n",
       " 'interview': 989,\n",
       " 'lukt': 990,\n",
       " 'geldt': 991,\n",
       " 'zoiets': 992,\n",
       " 'bestaan': 993,\n",
       " 'behalve': 994,\n",
       " 'game': 995,\n",
       " 'handig': 996,\n",
       " 'check': 997,\n",
       " 'nederlands': 998,\n",
       " 'persoonlijk': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250479"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(model.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['</s>',\n",
       " 'de',\n",
       " '<mention>',\n",
       " '<url>',\n",
       " 'een',\n",
       " 'het',\n",
       " 'en',\n",
       " 'van',\n",
       " 'in',\n",
       " 'ik',\n",
       " 'is',\n",
       " 'op',\n",
       " 'dat',\n",
       " 'je',\n",
       " 'voor',\n",
       " 'met',\n",
       " 'niet',\n",
       " 'te',\n",
       " 'zijn',\n",
       " 'die',\n",
       " 'maar',\n",
       " 'ook',\n",
       " 'er',\n",
       " 'als',\n",
       " 'om',\n",
       " 'bij',\n",
       " 'aan',\n",
       " 'rt',\n",
       " 'dan',\n",
       " 'wat',\n",
       " 'nog',\n",
       " 'wel',\n",
       " 'ze',\n",
       " 'dit',\n",
       " 'naar',\n",
       " 'of',\n",
       " 'we',\n",
       " 'over',\n",
       " 'heb',\n",
       " 'al',\n",
       " 'kan',\n",
       " 'heeft',\n",
       " 'zo',\n",
       " 'uit',\n",
       " 'mijn',\n",
       " 'nu',\n",
       " 'meer',\n",
       " 'door',\n",
       " 'was',\n",
       " 'deze',\n",
       " 'geen',\n",
       " 'hij',\n",
       " 'hebben',\n",
       " 'weer',\n",
       " 'ben',\n",
       " 'moet',\n",
       " 'goed',\n",
       " 'wordt',\n",
       " 'worden',\n",
       " 'dus',\n",
       " 'gaat',\n",
       " 'toch',\n",
       " 'veel',\n",
       " 'echt',\n",
       " 'gaan',\n",
       " 'zou',\n",
       " 'kunnen',\n",
       " 'na',\n",
       " 'daar',\n",
       " 'wil',\n",
       " 'hoe',\n",
       " 'via',\n",
       " 'hier',\n",
       " 'vind',\n",
       " 'mensen',\n",
       " 'doen',\n",
       " 'nieuwe',\n",
       " 'waar',\n",
       " 'tot',\n",
       " 'jaar',\n",
       " 'eens',\n",
       " 'mij',\n",
       " 'haar',\n",
       " 'heel',\n",
       " 'gewoon',\n",
       " 'me',\n",
       " 'alleen',\n",
       " 'had',\n",
       " 'maken',\n",
       " 'mee',\n",
       " 'tegen',\n",
       " 'hun',\n",
       " 'jij',\n",
       " 'komt',\n",
       " 'even',\n",
       " '1',\n",
       " 'wij',\n",
       " 'ons',\n",
       " 'ja',\n",
       " 'zal',\n",
       " 'iets',\n",
       " 'altijd',\n",
       " 'moeten',\n",
       " '2',\n",
       " 'onze',\n",
       " 'u',\n",
       " 'vandaag',\n",
       " 'zich',\n",
       " 'zelf',\n",
       " 'staat',\n",
       " 'ga',\n",
       " 'andere',\n",
       " 'zien',\n",
       " 'omdat',\n",
       " 'weet',\n",
       " 'komen',\n",
       " 'tijd',\n",
       " 'hem',\n",
       " 'alle',\n",
       " 'jullie',\n",
       " 'net',\n",
       " 'eerste',\n",
       " 'want',\n",
       " 'leuk',\n",
       " 'zit',\n",
       " 'alles',\n",
       " 'af',\n",
       " 'man',\n",
       " 'werd',\n",
       " 'denk',\n",
       " 'twee',\n",
       " 'laat',\n",
       " 'mag',\n",
       " 'onder',\n",
       " 'terug',\n",
       " 'dag',\n",
       " 'zie',\n",
       " 'nederland',\n",
       " 'nooit',\n",
       " 'wie',\n",
       " 'zon',\n",
       " 'weg',\n",
       " 'beter',\n",
       " 'zeker',\n",
       " 'willen',\n",
       " 'waarom',\n",
       " 'keer',\n",
       " 'iemand',\n",
       " 'hebt',\n",
       " '3',\n",
       " 'zoals',\n",
       " 'mooi',\n",
       " 'lekker',\n",
       " 'eigen',\n",
       " 'anders',\n",
       " 'staan',\n",
       " 'doet',\n",
       " 'tijdens',\n",
       " 'toen',\n",
       " 'mooie',\n",
       " 'grote',\n",
       " 't',\n",
       " 'kijken',\n",
       " 'zonder',\n",
       " 'allemaal',\n",
       " 'misschien',\n",
       " 'iedereen',\n",
       " 'zij',\n",
       " 'laten',\n",
       " 'helemaal',\n",
       " 'krijgen',\n",
       " 'verder',\n",
       " 'natuurlijk',\n",
       " 'binnen',\n",
       " 'leven',\n",
       " 'maakt',\n",
       " 'graag',\n",
       " 'weten',\n",
       " 'goede',\n",
       " '#nieuwstwitter',\n",
       " 'hoor',\n",
       " 'laatste',\n",
       " 'zeggen',\n",
       " 'zegt',\n",
       " 'snel',\n",
       " 'bent',\n",
       " 'toe',\n",
       " 'nou',\n",
       " 'kinderen',\n",
       " 'waren',\n",
       " 'erg',\n",
       " 'vinden',\n",
       " 'werk',\n",
       " 'jou',\n",
       " 'video',\n",
       " 'krijgt',\n",
       " 'samen',\n",
       " 'elkaar',\n",
       " 'nodig',\n",
       " 'video_leuk',\n",
       " 'hele',\n",
       " 'tussen',\n",
       " 'vanaf',\n",
       " 'zitten',\n",
       " 'beetje',\n",
       " 'minder',\n",
       " 'doe',\n",
       " 'niets',\n",
       " '4',\n",
       " 'geven',\n",
       " 'geld',\n",
       " 'wanneer',\n",
       " 'eigenlijk',\n",
       " 'kijk',\n",
       " 'vaak',\n",
       " 'beste',\n",
       " 'vraag',\n",
       " 'kom',\n",
       " 'eerst',\n",
       " 'nee',\n",
       " 'week',\n",
       " '10',\n",
       " '5',\n",
       " 'vooral',\n",
       " 'bijna',\n",
       " 'morgen',\n",
       " 'zelfs',\n",
       " 'blijft',\n",
       " 'huis',\n",
       " 'uur',\n",
       " 'mn',\n",
       " 'werken',\n",
       " 'lang',\n",
       " 'kunt',\n",
       " 'volgens',\n",
       " 'kun',\n",
       " 'achter',\n",
       " 'best',\n",
       " 'niks',\n",
       " 'gedaan',\n",
       " 'hoop',\n",
       " 'blijven',\n",
       " 'gemaakt',\n",
       " 'foto',\n",
       " 'ging',\n",
       " 'gezien',\n",
       " 'geeft',\n",
       " 'ziet',\n",
       " 'auto',\n",
       " 'houden',\n",
       " 'geweest',\n",
       " 'vrouw',\n",
       " '2017',\n",
       " 'nog_steeds',\n",
       " 'kon',\n",
       " 'mogelijk',\n",
       " 'genoeg',\n",
       " 'he',\n",
       " 'kwam',\n",
       " 'uw',\n",
       " 'jouw',\n",
       " 'politie',\n",
       " 'spelen',\n",
       " 'ajax',\n",
       " 'vragen',\n",
       " 'welke',\n",
       " 'zeg',\n",
       " 'soms',\n",
       " 'nemen',\n",
       " 'pas',\n",
       " 'nieuws',\n",
       " 'gelukkig',\n",
       " 'terwijl',\n",
       " 'nieuw',\n",
       " 'denken',\n",
       " 'amsterdam',\n",
       " 'krijg',\n",
       " 'lees',\n",
       " 'thuis',\n",
       " 'open',\n",
       " 'zullen',\n",
       " 'drie',\n",
       " 'blij',\n",
       " 'ligt',\n",
       " 'aantal',\n",
       " 'lijkt',\n",
       " 'hadden',\n",
       " 'helaas',\n",
       " 'vast',\n",
       " 'eten',\n",
       " 'haha',\n",
       " 'gehad',\n",
       " 'weinig',\n",
       " 'moment',\n",
       " 'werkt',\n",
       " 'klaar',\n",
       " 'eerder',\n",
       " 'inderdaad',\n",
       " '12',\n",
       " 'dagen',\n",
       " 'mogen',\n",
       " 'gelijk',\n",
       " 'ooit',\n",
       " 'plaats',\n",
       " 'leuke',\n",
       " 'steeds',\n",
       " 'vanavond',\n",
       " 'dingen',\n",
       " 'daarom',\n",
       " 'buiten',\n",
       " 'kans',\n",
       " 'juist',\n",
       " 'vindt',\n",
       " 'land',\n",
       " 'nl',\n",
       " 'gebruik',\n",
       " 'groot',\n",
       " 'word',\n",
       " 'rond',\n",
       " 'extra',\n",
       " 'moest',\n",
       " '6',\n",
       " 'probleem',\n",
       " 'artikel',\n",
       " 'men',\n",
       " 'zetten',\n",
       " 'zin',\n",
       " 'vrouwen',\n",
       " 'halen',\n",
       " 'ander',\n",
       " 'vond',\n",
       " 'fotos',\n",
       " 'zeer',\n",
       " '20',\n",
       " 'vanuit',\n",
       " 'wereld',\n",
       " 'zondag',\n",
       " 'duidelijk',\n",
       " 'lezen',\n",
       " 'zouden',\n",
       " 'gemeente',\n",
       " 'paar',\n",
       " 'zoveel',\n",
       " 'enige',\n",
       " 'fijn',\n",
       " 'later',\n",
       " 'dacht',\n",
       " 'zaterdag',\n",
       " 'naam',\n",
       " 'daarna',\n",
       " 'vrij',\n",
       " 'naast',\n",
       " 'onderzoek',\n",
       " 'wedstrijd',\n",
       " 'prima',\n",
       " 'deel',\n",
       " 'school',\n",
       " 'verhaal',\n",
       " 'precies',\n",
       " 'zei',\n",
       " 'wachten',\n",
       " 'lopen',\n",
       " 'maak',\n",
       " 'gebruiken',\n",
       " 'seizoen',\n",
       " 'bekend',\n",
       " 'boek',\n",
       " 'begin',\n",
       " '#actueel',\n",
       " 'start',\n",
       " 'houdt',\n",
       " 'kleine',\n",
       " 'zet',\n",
       " 'niemand',\n",
       " 'valt',\n",
       " 'bijvoorbeeld',\n",
       " 'horen',\n",
       " 'oude',\n",
       " 'kreeg',\n",
       " 'mannen',\n",
       " 'nederlandse',\n",
       " 'online',\n",
       " 'wilde',\n",
       " 'gratis',\n",
       " 'zat',\n",
       " 'n',\n",
       " 'moeder',\n",
       " 'hard',\n",
       " 'helpen',\n",
       " 'zodat',\n",
       " 'dank',\n",
       " 'per',\n",
       " 'gisteren',\n",
       " 'a',\n",
       " '7',\n",
       " 'feyenoord',\n",
       " 'vol',\n",
       " 'wilt',\n",
       " 'kind',\n",
       " 'zag',\n",
       " 'stad',\n",
       " '8',\n",
       " 'inmiddels',\n",
       " 'top',\n",
       " 'namelijk',\n",
       " 'rijden',\n",
       " 'team',\n",
       " 'echter',\n",
       " 'tweede',\n",
       " 'bezig',\n",
       " 'trump',\n",
       " 'hand',\n",
       " 'elke',\n",
       " 'zn',\n",
       " 'kopen',\n",
       " 'sinds',\n",
       " 'ie',\n",
       " 'bedrijf',\n",
       " 'meteen',\n",
       " 'jaren',\n",
       " 'idee',\n",
       " 'volgende',\n",
       " 'rotterdam',\n",
       " 'club',\n",
       " 'jammer',\n",
       " 'straks',\n",
       " 'twitter',\n",
       " 'volgens_mij',\n",
       " 'afspeellijst',\n",
       " 'gebruikt',\n",
       " 'zoeken',\n",
       " 'bedankt',\n",
       " 'boven',\n",
       " 'ouders',\n",
       " 'opnieuw',\n",
       " 'groep',\n",
       " 'video_toegevoegd_aan',\n",
       " 'langs',\n",
       " 'begint',\n",
       " 'super',\n",
       " 'beginnen',\n",
       " 'ff',\n",
       " 'betalen',\n",
       " 'stond',\n",
       " 'echte',\n",
       " 'weekend',\n",
       " 'm',\n",
       " 'water',\n",
       " 'neemt',\n",
       " 'vrijdag',\n",
       " 'liggen',\n",
       " 'druk',\n",
       " 'waarschijnlijk',\n",
       " 'zorgen',\n",
       " 'stuk',\n",
       " 'zorg',\n",
       " 'vakantie',\n",
       " 'wist',\n",
       " 'eindelijk',\n",
       " 'manier',\n",
       " 'snap',\n",
       " 'verwacht',\n",
       " 'speelt',\n",
       " 'live',\n",
       " '15',\n",
       " 'slecht',\n",
       " 'direct',\n",
       " 'heerlijk',\n",
       " 'hou',\n",
       " 'belangrijk',\n",
       " 'moeilijk',\n",
       " 'rest',\n",
       " 'werden',\n",
       " '#nieuws',\n",
       " 'meisje',\n",
       " 'uiteindelijk',\n",
       " 'geef',\n",
       " 'vier',\n",
       " 'neem',\n",
       " 'leren',\n",
       " 'problemen',\n",
       " '#voetbal',\n",
       " 'prijs',\n",
       " 'normaal',\n",
       " 'totaal',\n",
       " 'toekomst',\n",
       " 'heen',\n",
       " 'hoofd',\n",
       " 'koop',\n",
       " 'bericht',\n",
       " 'europa',\n",
       " 'geworden',\n",
       " 'dood',\n",
       " 'actie',\n",
       " 'mocht',\n",
       " '#vacature',\n",
       " '30',\n",
       " 'proberen',\n",
       " 'loopt',\n",
       " 'gevonden',\n",
       " 'winnen',\n",
       " 'aandacht',\n",
       " 'maandag',\n",
       " 'klopt',\n",
       " 'zoek_naar',\n",
       " 'vrienden',\n",
       " 'gevoel',\n",
       " 'nummer',\n",
       " 'denkt',\n",
       " 'plek',\n",
       " 'vroeg',\n",
       " 'volgen',\n",
       " 'reactie',\n",
       " 'partij',\n",
       " 'genieten',\n",
       " 'tv',\n",
       " 'soort',\n",
       " 'spelers',\n",
       " 'reden',\n",
       " 'liever',\n",
       " 'mis',\n",
       " 'da',\n",
       " 'geloof',\n",
       " 'gek',\n",
       " 'deed',\n",
       " 'brengen',\n",
       " 'vs',\n",
       " 'trouwens',\n",
       " 'utrecht',\n",
       " 'avond',\n",
       " '100',\n",
       " 'waardoor',\n",
       " 'blijkt',\n",
       " 'ervaring',\n",
       " 'programma',\n",
       " 'meeste',\n",
       " 'antwoord',\n",
       " 'vanwege',\n",
       " 'vervolgens',\n",
       " 'website',\n",
       " 'x',\n",
       " 'waarin',\n",
       " 'muziek',\n",
       " 'richting',\n",
       " 'bedrijven',\n",
       " 'anderen',\n",
       " 'zichzelf',\n",
       " 'jezelf',\n",
       " 'ergens',\n",
       " 'delen',\n",
       " '2016',\n",
       " 'overigens',\n",
       " 'euro',\n",
       " 'land_nederland_geslacht_vrouw',\n",
       " '25',\n",
       " '11',\n",
       " 'basis',\n",
       " 'stemmen',\n",
       " 'dezelfde',\n",
       " 'bestaat',\n",
       " 'waarbij',\n",
       " 'vader',\n",
       " 'psv',\n",
       " 'beeld',\n",
       " 'hoeveel',\n",
       " 'kosten',\n",
       " 'gesprek',\n",
       " 'daarnaast',\n",
       " 'geval',\n",
       " 'maand',\n",
       " 'familie',\n",
       " 'jongens',\n",
       " 'praten',\n",
       " 'ken',\n",
       " 'prachtige',\n",
       " 'begonnen',\n",
       " 'eu',\n",
       " 'hen',\n",
       " 'langer',\n",
       " 'd',\n",
       " '#nieuws_#nederland',\n",
       " 'geweldig',\n",
       " 'alsof',\n",
       " 'hoeft',\n",
       " '>',\n",
       " 'hopelijk',\n",
       " 'punt',\n",
       " '22',\n",
       " 'film',\n",
       " 'woord',\n",
       " 'vorig_jaar',\n",
       " 'einde',\n",
       " 'donderdag',\n",
       " 'maakte',\n",
       " 'zowel',\n",
       " 'kiezen',\n",
       " 'hetzelfde',\n",
       " 'trots',\n",
       " 'app',\n",
       " 'ogen',\n",
       " 'vergeten',\n",
       " 'bed',\n",
       " 'ver',\n",
       " 'gekregen',\n",
       " '9',\n",
       " 'slapen',\n",
       " 'lijkt_me',\n",
       " 'woensdag',\n",
       " 'verschillende',\n",
       " 'succes',\n",
       " 'vriend',\n",
       " 'jonge',\n",
       " 'makkelijk',\n",
       " 'tweet',\n",
       " 'stellen',\n",
       " 'ruimte',\n",
       " 'politiek',\n",
       " 'enkel',\n",
       " 'voorbij',\n",
       " 'vijf',\n",
       " 'hahaha',\n",
       " 'jong',\n",
       " 'the',\n",
       " 'internet',\n",
       " 'liefde',\n",
       " 'belgie',\n",
       " 'oh',\n",
       " 'grootste',\n",
       " 'mens',\n",
       " 'daarmee',\n",
       " 'slechts',\n",
       " 'plaatsen',\n",
       " 'gezegd',\n",
       " 'alweer',\n",
       " 'los',\n",
       " 'stoppen',\n",
       " 'sorry',\n",
       " 'recht',\n",
       " 'gebeuren',\n",
       " '50',\n",
       " 'bank',\n",
       " 'plan',\n",
       " 'hoort',\n",
       " 'persoon',\n",
       " 'mening',\n",
       " 'woorden',\n",
       " 'heel_erg',\n",
       " 'ondanks',\n",
       " 'links',\n",
       " 'zoek',\n",
       " 'den_haag',\n",
       " 'facebook',\n",
       " 'bang',\n",
       " 'punten',\n",
       " 'voordat',\n",
       " 'betekent',\n",
       " 'afgelopen',\n",
       " 'gebeurt',\n",
       " 'telefoon',\n",
       " 'ontvangen',\n",
       " 'kamer',\n",
       " 'last',\n",
       " 'idd',\n",
       " 'terecht',\n",
       " 'doel',\n",
       " 'trein',\n",
       " 'bekijk',\n",
       " 'bezoek',\n",
       " 'erbij',\n",
       " 'buurt',\n",
       " 'wonen',\n",
       " 'stem',\n",
       " 'fout',\n",
       " 'zaken',\n",
       " 'informatie',\n",
       " 'rust',\n",
       " 'contact',\n",
       " 'zomer',\n",
       " 'vroeger',\n",
       " 'keuze',\n",
       " 'ineens',\n",
       " 'v',\n",
       " 'prachtig',\n",
       " 'blijkbaar',\n",
       " 'klein',\n",
       " 'oud',\n",
       " 'woning',\n",
       " 'ipv',\n",
       " 'etc',\n",
       " 'ieder_geval',\n",
       " 'feit',\n",
       " 'vertellen',\n",
       " 'nadat',\n",
       " 'volledig',\n",
       " 'burgemeester',\n",
       " 'kut',\n",
       " 'neuken',\n",
       " 'oplossing',\n",
       " '@',\n",
       " 'stel',\n",
       " 'ongeveer',\n",
       " 'hoog',\n",
       " 'site',\n",
       " 'dit_soort',\n",
       " 'hart',\n",
       " 'winkel',\n",
       " 'overal',\n",
       " 'oke',\n",
       " 'kennis',\n",
       " 'dinsdag',\n",
       " 'uiteraard',\n",
       " 'tips',\n",
       " 'straat',\n",
       " 'aanwezig',\n",
       " '2018',\n",
       " 'markt',\n",
       " 'vvd',\n",
       " 'ruim',\n",
       " '13',\n",
       " 'blijf',\n",
       " 'wellicht',\n",
       " 'daarbij',\n",
       " 'binnenkort',\n",
       " 'oa',\n",
       " 'noemen',\n",
       " 'schrijven',\n",
       " 'aldus',\n",
       " 'pakken',\n",
       " 'enorm',\n",
       " 'blog',\n",
       " 'sommige',\n",
       " 'vriendin',\n",
       " 'mezelf',\n",
       " 'jongen',\n",
       " '18',\n",
       " 'grond',\n",
       " 'handen',\n",
       " 'meestal',\n",
       " 'vertrouwen',\n",
       " 'kost',\n",
       " 'bijzonder',\n",
       " 'gekomen',\n",
       " 'benieuwd',\n",
       " 'groningen',\n",
       " 'vallen',\n",
       " 'vraagt',\n",
       " 'fiets',\n",
       " 'betreft',\n",
       " 'omgeving',\n",
       " 'beschikbaar',\n",
       " 'kort',\n",
       " 'dochter',\n",
       " 'sowieso',\n",
       " 'licht',\n",
       " 'gegaan',\n",
       " 'welkom',\n",
       " 'gegeven',\n",
       " 'tegenwoordig',\n",
       " 'gezellig',\n",
       " 'baan',\n",
       " 'beide',\n",
       " 'duitsland',\n",
       " 'miljoen',\n",
       " 'helpt',\n",
       " 'sterk',\n",
       " 'hond',\n",
       " 'hopen',\n",
       " 'gebied',\n",
       " 'vanmiddag',\n",
       " 'bus',\n",
       " 'voelt',\n",
       " 'media',\n",
       " 'lastig',\n",
       " 'raad',\n",
       " 'vele',\n",
       " 'sturen',\n",
       " 'nie',\n",
       " 'wakker',\n",
       " 'kijkt',\n",
       " '40',\n",
       " 'maanden',\n",
       " 'das',\n",
       " 'organisatie',\n",
       " 'o',\n",
       " 'update',\n",
       " 'vorm',\n",
       " 'nacht',\n",
       " 'link',\n",
       " 'slag',\n",
       " 'gezicht',\n",
       " 'overheid',\n",
       " 'verschil',\n",
       " '14',\n",
       " 'vaker',\n",
       " 'boeken',\n",
       " '16',\n",
       " 'stelt',\n",
       " 'voorkomen',\n",
       " 'vd',\n",
       " 'volg',\n",
       " 'huidige',\n",
       " 'deur',\n",
       " 'serieus',\n",
       " 'wint',\n",
       " 'lol',\n",
       " 'daarvoor',\n",
       " 'kant',\n",
       " 'b',\n",
       " 'kent',\n",
       " 'p',\n",
       " 'ofzo',\n",
       " 'jaar_geleden',\n",
       " 'enkele',\n",
       " 'klanten',\n",
       " 'stap',\n",
       " 'hulp',\n",
       " 'god',\n",
       " 'zoon',\n",
       " 'rutte',\n",
       " 'ding',\n",
       " 'klinkt',\n",
       " 'zoekt',\n",
       " 'rustig',\n",
       " 'project',\n",
       " 'gekocht',\n",
       " 'jan',\n",
       " 'dicht',\n",
       " 'islam',\n",
       " 'ene',\n",
       " 'leggen',\n",
       " 'vertelt',\n",
       " 'kwamen',\n",
       " 'probeer',\n",
       " 'spel',\n",
       " 'voetbal',\n",
       " 'kwijt',\n",
       " 'begon',\n",
       " 'lief',\n",
       " 'jongeren',\n",
       " 'wacht',\n",
       " 'konden',\n",
       " 'stuur',\n",
       " 'winst',\n",
       " 'regio',\n",
       " 'gezet',\n",
       " 'moeite',\n",
       " 'leden',\n",
       " 'heet',\n",
       " 'begrijp',\n",
       " 'aangezien',\n",
       " 'geniet',\n",
       " 'gaf',\n",
       " 'pvv',\n",
       " 'trekken',\n",
       " 'merk',\n",
       " 'kop',\n",
       " 'hallo',\n",
       " 'spreken',\n",
       " 'bedoel',\n",
       " 'derde',\n",
       " 'pijn',\n",
       " 'college',\n",
       " 'gelezen_via',\n",
       " 'lichaam',\n",
       " 'gingen',\n",
       " 'momenteel',\n",
       " 'speler',\n",
       " 'kwaliteit',\n",
       " 'brand',\n",
       " 'liefst',\n",
       " '21',\n",
       " 'moslims',\n",
       " 'zaak',\n",
       " 'gehoord',\n",
       " 'ge',\n",
       " 'weken',\n",
       " 'verkopen',\n",
       " 'systeem',\n",
       " 'samenwerking',\n",
       " 'dames',\n",
       " 'wet',\n",
       " 'veranderen',\n",
       " 'collegas',\n",
       " 'waarvan',\n",
       " 'k',\n",
       " 'past',\n",
       " 'voorbeeld',\n",
       " 'situatie',\n",
       " 'autos',\n",
       " 'bovendien',\n",
       " 'brengt',\n",
       " 'meerdere',\n",
       " 'meisjes',\n",
       " 'dankzij',\n",
       " 'ondertussen',\n",
       " 'houd',\n",
       " 'producten',\n",
       " 'oranje',\n",
       " 'info',\n",
       " 'turkije',\n",
       " 'zomaar',\n",
       " 'qua',\n",
       " 'filmpje',\n",
       " 'rol',\n",
       " 'plannen',\n",
       " 'daardoor',\n",
       " 'groter',\n",
       " 'teveel',\n",
       " 'sta',\n",
       " 'tip',\n",
       " 'tja',\n",
       " 'locatie',\n",
       " 'nergens',\n",
       " 'advies',\n",
       " 'minister',\n",
       " 'gezocht',\n",
       " 'veilig',\n",
       " 'serie',\n",
       " 'gebeurd',\n",
       " 'september',\n",
       " 'elke_dag',\n",
       " 'gefeliciteerd',\n",
       " 'rechter',\n",
       " 'bouwen',\n",
       " 'partijen',\n",
       " 'lid',\n",
       " 'betaald',\n",
       " '23',\n",
       " 'bv',\n",
       " 'wilders',\n",
       " 'ieder',\n",
       " 'melding',\n",
       " 'volgende_week',\n",
       " 'voel',\n",
       " 'gelezen',\n",
       " 'max',\n",
       " 'juiste',\n",
       " 'voelen',\n",
       " 'resultaat',\n",
       " 'wedstrijden',\n",
       " 'bepaalde',\n",
       " 'centrum',\n",
       " 'zoekt_manmeer_over',\n",
       " 'zorgt',\n",
       " 'bleek',\n",
       " 'bellen',\n",
       " 'tafel',\n",
       " 'stil',\n",
       " 'kleur',\n",
       " 'flink',\n",
       " 'eerlijk',\n",
       " 'omg',\n",
       " 'zolang',\n",
       " 'stukje',\n",
       " 'volgt',\n",
       " 'bieden',\n",
       " 'lachen',\n",
       " 'regelmatig',\n",
       " '#voetbalnt',\n",
       " 'eindhoven',\n",
       " 'sport',\n",
       " 'liet',\n",
       " 'zwaar',\n",
       " '17',\n",
       " 's',\n",
       " 'haalt',\n",
       " 'bal',\n",
       " 'reacties',\n",
       " 'belang',\n",
       " 'dieren',\n",
       " 'eind',\n",
       " 'voldoende',\n",
       " 'gewonnen',\n",
       " 'iedere',\n",
       " 'raar',\n",
       " 'hoewel',\n",
       " 'titel',\n",
       " 'ok',\n",
       " 'medewerkers',\n",
       " 'besluit',\n",
       " 'reageren',\n",
       " 'bedoeld',\n",
       " 'nederlanders',\n",
       " 'rij',\n",
       " 'kapot',\n",
       " 'niveau',\n",
       " 'onderwijs',\n",
       " 'elk',\n",
       " 'kennen',\n",
       " 'interview',\n",
       " 'lukt',\n",
       " 'geldt',\n",
       " 'zoiets',\n",
       " 'bestaan',\n",
       " 'behalve',\n",
       " 'game',\n",
       " 'handig',\n",
       " 'check',\n",
       " 'nederlands',\n",
       " 'persoonlijk',\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we just need the list of words. end. \n",
    "# model.index_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "char = CharLengthRatio(\"train\", 0.8)\n",
    "sentences_pair = char.get_ratio(sentences_pair)\n",
    "sentences_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "word_length = WordLengthRatio(\"train\", 0.8)\n",
    "sentences_pair = word_length.get_ratio(sentences_pair)\n",
    "sentences_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "levenshtein = LevenshteinRatio(\"train\", 0.8)\n",
    "sentences_pair = levenshtein.get_ratio(sentences_pair)\n",
    "sentences_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dependency = DependencyTreeDepthRatio(\"train\", 0.8)\n",
    "sentences_pair = dependency.get_ratio(sentences_pair)\n",
    "sentences_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "word_rank = WordRankRatio(\"train\", 0.8)\n",
    "sentences_pair = word_rank.get_ratio(sentences_pair)\n",
    "sentences_pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Exploring features values from simpleText shared task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# SIMPLETEXT_DATASET_PATH = DATASETS_PATH / \"simpleText\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIKILARGE_DATASET_PATH = DATASETS_PATH / \"wikilarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_text = pd.read_csv(WIKILARGE_DATASET_PATH / \"wikilarge.train.orig.txt\", header=None, sep=\"\\t\", names=[\"original_text\"])\n",
    "simple_text = pd.read_csv(WIKILARGE_DATASET_PATH / \"wikilarge.train.simp.txt\", header=None, sep=\"\\t\",names=[\"simple_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# complex_text = pd.read_csv(SIMPLETEXT_DATASET_PATH / \"simpleText.train.complex.txt\", header=None, sep=\"\\t\", names=[\"original_text\"])\n",
    "# simple_text = pd.read_csv(SIMPLETEXT_DATASET_PATH / \"simpleText.train.simple.txt\", header=None, sep=\"\\t\",names=[\"simple_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sentences_pairs = pd.concat([complex_text, simple_text], axis=1)\n",
    "sentences_pairs = sentences_pairs[1:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for i,row in sentences_pairs.iterrows():\n",
    "    sentences_pair = dict(original_text=row['original_text'], simple_text=row['simple_text'])\n",
    "    sentences_pair = char.get_ratio(sentences_pair)\n",
    "    sentences_pair = word_length.get_ratio(sentences_pair)\n",
    "    sentences_pair = levenshtein.get_ratio(sentences_pair)\n",
    "    sentences_pair = dependency.get_ratio(sentences_pair)\n",
    "    sentences_pair = word_rank.get_ratio(sentences_pair)\n",
    "    features = sentences_pair[\"original_text_preprocessed\"].strip().split(\" \")\n",
    "    instance = dict(feature.split(\"_\") for feature in features)\n",
    "    results.append(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(results)\n",
    "results_df = pd.DataFrame(results).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Character Length Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "sns.distplot(results_df[\"CLR\"])\n",
    "fig.legend(labels=['Char Length'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "sns.distplot(results_df[\"WLR\"],label=\"Word Length\")\n",
    "fig.legend(labels=['Word Length'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "sns.distplot(results_df[\"LR\"])\n",
    "fig.legend(labels=['Levenshtein'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "sns.distplot(results_df[\"LR\"])\n",
    "fig.legend(labels=['Levenshtein'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "sns.distplot(results_df[\"DTDR\"])\n",
    "fig.legend(labels=['Deep Tree'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "sns.distplot(results_df[\"WRR\"])\n",
    "fig.legend(labels=['Word Rank'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
